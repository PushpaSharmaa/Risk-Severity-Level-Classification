üîç Risk Severity Level Classification

This project focuses on predicting the severity level of incidents (CRITICAL, HIGH, MEDIUM, LOW) based on their short descriptions.
It uses machine learning models with hyperparameter tuning and compares multiple classifiers to identify the best-performing one.


üìå Objective

To build an automated classification system that processes incident text data, applies TF-IDF feature extraction, trains multiple models, evaluates performance metrics, and saves the best model for deployment or future use.


üìÇ Dataset

The project combines multiple CSV datasets containing enriched incident reports:
Key Columns:
	‚Ä¢	short_description ‚Üí Incident description (text)
	‚Ä¢	severity ‚Üí Target variable (CRITICAL, HIGH, MEDIUM, LOW)


 ‚öôÔ∏è Workflow
	1.	Data Loading & Preprocessing
	‚Ä¢	Combines multiple CSV files
	‚Ä¢	Removes rows with missing values
 
	2.	Feature Engineering
	‚Ä¢	Applies TF-IDF Vectorization to convert text into numerical features
 
	3.	Model Training & Hyperparameter Tuning
	‚Ä¢	Models Used:
	‚Ä¢	Multinomial Naive Bayes
	‚Ä¢	Logistic Regression
	‚Ä¢	Random Forest
	‚Ä¢	Support Vector Classifier (SVC)
	‚Ä¢	Gradient Boosting
 
	4.	Evaluation
	‚Ä¢	Accuracy, Precision, Recall, F1-Score
	‚Ä¢	Confusion Matrices
	‚Ä¢	Class Distribution Visualization
 
	5.	Model Selection & Saving
	‚Ä¢	Saves best model (best_model.pkl) and TF-IDF vectorizer (tfidf.pkl)
	‚Ä¢	Exports performance metrics to model_scores.csv


 üìä Visualizations
	‚Ä¢	Severity distribution bar charts
	‚Ä¢	Confusion matrix heatmaps
	‚Ä¢	Comparison of model performance (Accuracy, Precision, Recall, F1)


 üõ†Ô∏è Tech Stack
Python
pandas, numpy: Data manipulation
matplotlib, seaborn: Visualizations
scikit-learn: ML models, hyperparameter tuning, evaluation
joblib: Model serialization
